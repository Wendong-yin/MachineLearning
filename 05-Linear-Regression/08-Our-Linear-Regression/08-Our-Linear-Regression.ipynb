{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 08 实现我们自己的 Linear Regression\n",
    "\n",
    "### 一元线性回归\n",
    "![IMAGE](https://farm2.staticflickr.com/1736/27812680287_f3390e64a7_o.png)\n",
    "\n",
    "### 多元线性回归\n",
    "x 从一个点，变成一个向量\n",
    "![IMAGE](https://farm2.staticflickr.com/1748/40872266130_d6cd7cac7f_o.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一元线性回归，我们参数是 a 和 b\n",
    "\n",
    "多元线性回归，参数是$\\theta_{0}\\theta_{1}\\theta_{2}...\\theta_{n}$\n",
    "\n",
    "### 多元线性回归的目标\n",
    "**针对第 i 个样本：**\n",
    "![IMAGE](https://farm2.staticflickr.com/1725/41781668805_e7da0b997d_o.png)\n",
    "> $\\theta$原本是一个行向量，转置后变成一个列向量，放在右边，等待与数据进行点乘\n",
    "\n",
    "![IMAGE](https://farm2.staticflickr.com/1748/41781728685_4c4e2c65e8_o.png)\n",
    "\n",
    "**推广到所有样本**\n",
    "> $X_{b}$ 和 $X$的区别是多了 一列1\n",
    "\n",
    "![IMAGE](https://farm2.staticflickr.com/1731/28808265538_2fcc1e7731_o.png)\n",
    "\n",
    "对比\n",
    "![IMAGE](https://farm2.staticflickr.com/1723/42006651364_59291395b3_o.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 目标函数的向量化\n",
    "![IMAGE](https://farm2.staticflickr.com/1729/28808353058_ed0cf16e8f_o.png)\n",
    "最终得到的是一个数字\n",
    "\n",
    "### 对目标函数求导\n",
    "![IMAGE](https://farm2.staticflickr.com/1723/27812966087_816d2295a6_o.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "# 左边添加1列\n",
    "X_b = np.hstack([np.ones((len(X_train), 1)), X_train])\n",
    "# ❤️❤️ 核心计算\n",
    "self._theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train)\n",
    "```\n",
    "\n",
    "![IMAGE](https://farm2.staticflickr.com/1751/40872558980_844af755fd_o.png)\n",
    "![IMAGE](https://farm2.staticflickr.com/1760/27813082817_fc588e0846_o.png)\n",
    "* 缺点：这里的 n 是对行和列的一个普遍指代。如果数据量很高或者 feature 很多，都会导致时间时间复杂度很高，解决方法可以利用下一章的知识。实际情况中直接使用这种方法进行运算的很少很少。\n",
    "* 优点：因为 theta 是 x 的系数，没有量纲，所以不用进行归一化处理。\n",
    "\n",
    "![IMAGE](https://farm2.staticflickr.com/1727/40872651190_b92d082c52_o.png)\n",
    "\n",
    "有时候我们把截距和系数分别汇报给用户，并且系数可以反映不同 feature 的贡献程度。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用我们自己制作 Linear Regression\n",
    "\n",
    "代码参见 [这里](playML/LinearRegression.py)\n",
    "```python\n",
    "class LinearRegression:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"初始化Linear Regression模型\"\"\"\n",
    "        self.coef_ = None # theta 0 \n",
    "        self.intercept_ = None # theta 1~n\n",
    "        self._theta = None # 这是一个私有的变量, theta0~n\n",
    "\n",
    "    def fit_normal(self, X_train, y_train):\n",
    "        \"\"\"根据训练数据集X_train, y_train训练Linear Regression模型\"\"\"\n",
    "        assert X_train.shape[0] == y_train.shape[0], \\\n",
    "            \"the size of X_train must be equal to the size of y_train\"\n",
    "        # 左边添加1列\n",
    "        X_b = np.hstack([np.ones((len(X_train), 1)), X_train])\n",
    "        # ❤️❤️ 核心计算\n",
    "        self._theta = np.linalg.inv(X_b.T.dot(X_b)).dot(X_b.T).dot(y_train)\n",
    "\n",
    "        self.intercept_ = self._theta[0]\n",
    "        self.coef_ = self._theta[1:]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X_predict):\n",
    "        \"\"\"给定待预测数据集X_predict，返回表示X_predict的结果向量\"\"\"\n",
    "        assert self.intercept_ is not None and self.coef_ is not None, \\\n",
    "            \"must fit before predict!\"\n",
    "        assert X_predict.shape[1] == len(self.coef_), \\\n",
    "            \"the feature number of X_predict must be equal to X_train\"\n",
    "            \n",
    "            \n",
    "        # ❤️ 先补充一列\n",
    "        X_b = np.hstack([np.ones((len(X_predict), 1)), X_predict])\n",
    "        # ❤️ 点乘原来我们计算出来的 theta\n",
    "        return X_b.dot(self._theta)\n",
    "\n",
    "    def score(self, X_test, y_test):\n",
    "        \"\"\"根据测试数据集 X_test 和 y_test 确定当前模型的准确度\"\"\"\n",
    "\n",
    "        y_predict = self.predict(X_test)\n",
    "        return r2_score(y_test, y_predict)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"LinearRegression()\"\n",
    "\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "\n",
    "X = boston.data\n",
    "y = boston.target\n",
    "\n",
    "X = X[y < 50.0]\n",
    "y = y[y < 50.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(490, 13)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from playML.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, seed=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from playML.LinearRegression import LinearRegression\n",
    "\n",
    "reg = LinearRegression()\n",
    "# 这回我们使用全部X 中的列\n",
    "reg.fit_normal(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -1.18919477e-01,   3.63991462e-02,  -3.56494193e-02,\n",
       "         5.66737830e-02,  -1.16195486e+01,   3.42022185e+00,\n",
       "        -2.31470282e-02,  -1.19509560e+00,   2.59339091e-01,\n",
       "        -1.40112724e-02,  -8.36521175e-01,   7.92283639e-03,\n",
       "        -3.81966137e-01])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34.161435496224712"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.81298026026584658"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
